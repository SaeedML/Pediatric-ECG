import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from matplotlib import style
import seaborn as sns
import tensorflow as tf
from sklearn.model_selection import train_test_split, cross_val_predict
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from xgboost import XGBClassifier
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import  accuracy_score

df = pd.read_csv('/Users/saeed/Desktop/Ongoing Works/Pediatrics/P1.csv', skiprows=0)

df['sex'] = df['sex'].astype('category')
df['Target'] = df['Target'].astype('category')

X = df1.drop(['Target'], axis=1)
y = df1['Target']

encoder = LabelEncoder()
y = encoder.fit_transform(y)

df.info()

ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "TpTe").add_legend()
ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "QTc").add_legend()
ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "QTd").add_legend()
ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "TpTe/QT").add_legend()
ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "QRS dur").add_legend()
ax = sns.FacetGrid(df, hue="Target", size=6).map(sns.kdeplot, "PR int").add_legend()

sns.FacetGrid(df, hue="Target", size=5) \
   .map(plt.scatter,"QTd","TpTe/QT") \
   .add_legend()
   
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.3, random_state=0)
print('There are {} samples in the training set and {} samples in the test set'.format(
X_train.shape[0], X_test.shape[0]))
print()


lr_model = LogisticRegression()
lr_model.fit(x_train,y_train)
lr_predict = lr_model.predict(x_test)
print('Logistic Regression - ',accuracy_score(lr_predict,y_test))


svm_model = SVC(kernel='linear')
svm_model.fit(x_train,y_train)
svc_predict = svm_model.predict(x_test)
print('SVM - ',accuracy_score(svc_predict,y_test))


nb_model = GaussianNB()
nb_model.fit(x_train,y_train)
nb_predict = nb_model.predict(x_test)
print('Naive bayes - ',accuracy_score(nb_predict,y_test))


dt_model = DecisionTreeClassifier(max_leaf_nodes=3)
dt_model.fit(x_train,y_train)
dt_predict = dt_model.predict(x_test)
print('Decision Tree - ',accuracy_score(dt_predict,y_test))


rfc_model = RandomForestClassifier(max_depth=3)
rfc_model.fit(x_train,y_train)
rfc_predict = rfc_model.predict(x_test)
print('Random Forest - ',accuracy_score(rfc_predict,y_test))


knn_model = KNeighborsClassifier(n_neighbors=3)
knn_model.fit(x_train,y_train)
knn_predict = knn_model.predict(x_test)
print('knn - ',accuracy_score(knn_predict,y_test))


xg_model = xgb.XGBClassifier()
xg_model = xg_model.fit(x_train,y_train)
xg_model.score(x_test, y_test)
print(xg_model.feature_importances_)
